{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--XItMxuyuwY"
      },
      "source": [
        "#### Check if GPU is available\n",
        "If you are running this in gsds server, follow the instruction below to run jupyter notebook with GPU.\n",
        "\n",
        "https://gsds.gitbook.io/gsds/for-beginners/slurm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Install requried packages if not installed in your environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NgOYc32SGNgu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting beautifulsoup4 (from wikipedia)\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->wikipedia)\n",
            "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata\n",
            "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=956aa67cdf15022e21c5c55da59216b2ccce51a50da71bd5335ae9d40b01bcf3\n",
            "  Stored in directory: /home/jwjung/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\n",
            "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.5 wikipedia-1.4.0\n",
            "Requirement already satisfied: transformers in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/jw/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "# !pip install wikipedia\n",
        "# !pip install transformers\n",
        "# !pip install -q datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run this cell before you start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from collections import OrderedDict\n",
        "import wikipedia as wiki\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbC_lmmut0sf"
      },
      "source": [
        "# 1. Inference using a pre-trained Question Answering model \n",
        "\n",
        "In this problem, we will utilize a pre-trained BERT(Bidirectional Encoder Representations from Transformers) model for question answering. BERT excels in this task by leveraging its contextual understanding of language, employing techniques such as tokenization, segment embeddings, positional embeddings, and multi-head self-attention to capture intricate relationships between words. During the inference phase, the model predicts answer spans in a passage based on its extensive pre-trained knowledge and fine-tuned task-specific understanding. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twl2XFHPT1Lw"
      },
      "source": [
        "![1_cXDOP0gsE7Zp8-sgZqYfTA.webp](data:image/webp;base64,UklGRggmAABXRUJQVlA4WAoAAAAIAAAAUwEAGQEAVlA4ICglAACQrgCdASpUARoBPm0wlUekIqShJxGrsJANiWNu9JZ/wKcmh4xoAyoqJ/tP5FePGS/5n5D/kdzA3e/8Wvw8xQPA8qvqL/Dfl1/kPmD/uf2L92v6L9FD7gO3r/XvQn+zvq4/9T/O+2P/LeoB/0v4B6XXs5+gx+w/XE/3H/oekdqoXlX+i/kx5uf3/+9/lT2PnpT1/+Rv8hzJ9g3876Ify/7Jfjf7t+4/xl/w/89+WP4we5Pym/aftd+QX8n/jX91/M/+48cnuH+9/zvqC+nfy3/Jf2v/H/8n+9fID75/aPyY/f/51+sn+s+2n7Af4v/OP8b+af+I///vi+Kt98/53sB/yL+j/4D/I/43/b/4T///PF/if4r/R/sd7p/zL/C/8f/J/6X9p/sI/kX8//2n99/yn/y/zH/////3Sewn9yvYs/Yf/vHCSu+bvm75ulRMaBUlumAhy7PORBv/99sT9hOyVV5AN5DMc74aLblYwGTcP/XPuhDWOOwBzZfp76e+nvSTjL3Amdm1GDtYEWQLiU3Jl4JJbg/Cr854qPRbGvcpA6jsvjPvfoH+NHrSJ8DDQTAvl2k6EwL7qdJd1AjbSNqWW4xqevxC4uFdML+bGlXdp3k4GdB50OFHqKj1XhUEZPddxduIgJY8lJU3OQHCjXkHBMbBz2A/oGLDG4Wv7TG+SXZcsfMwrkRymVEeesUJlcGVXVajgRyrlHJWU56OYH6648iS1LMkMcy0ZviLmrFxYDaCFu/MDn7mFQ2q85O6Flw+IzgOqUFEJcHdAK7kNSeOTgWNIPyaX5tWjBzOzdKt0gOKOeHC3w7Npgv9XkNFjXDeQ/4zj4WyBVWcexhcXlTv6vnhqLrQSOO5efq34YusNIxz9RSmajwu8S13W1/Fn8i+yxfcx9ZFZ9HPNsaukI4JjVQkoF8Hd+747JvZe/xztgxI20tdy60/V0znGxj9UuWl2J2ZQM7Gl5o5R7IkVdhm+pHElEFdCgZ4MAy7L4rGIBbBfH/vZbMNgmLLsGqVeE0Tnbhtvn7QXP+W043as+Q0ZrCBL66jKuuXOSHjZy1/wmriE3KTIyYbFk0hE2QEiRwwzgKj3urU4HUjZTwZ7VARUFg5sMIJ4ecyJjEUoFuQ1DHWgDnpnXhHyYuSz6D7CrM5Rdf/FnT1z6JiQoLUagd/IqRjqRA3QRhu0VPKf7jI6xlJsbpSp43CrYerxigf+yedTRvOaqyaNpDgVta9zq4cnvFQnlvoTc9D7kLjbiz05F6qjaC5wBJNj8zbVjbMoTuKpBZxR7LVES1f9POwGYK0ZPVkjaqhN7zY6jVTk2N5mHQB66S1BMytSU4oEsfub2pi97oAw09iKlxqZZQsRromD74gxx/3EW+yTf/1XhicyZovJCA/QoYhXvbXW1cBzKPAS1HUIN8XmSijQsCmPJ7CUfZhfo5BM8OfD3E9jCb1rVqKPxyPvxAehsoA+LHZlBQ5MjkjU+I7R0Ucw/QBW2iCfbcXwV4jkeA0jn8qycXJemXYp5mVcBy5nf0gpFX1Q9wgVge9ltFcer3MQg1lAYflyHhhgNKK5l9OuvhuoRDw9reoDpOqos8qzV0QzxH6HDlrkNeQJNB0VMdZO8G0FL3XG+7t7N5j/pgcgYzV96/iyP5hvVX0N5YNyK+RUIDXhQr/ag0fMKULma23xDrn+XbXtCPzZn90UY/QbfbdSp8I33FIhfTgww+2ogo3fZ+KsfzT0UenmDAz84t/t35djKnMdry6yED0WAwNYWVMQAi3e/4uzCgaEpzQ1uq/vp7065I25E8MbRTSR6sjJXe/Wky3NJeBHq0IVjWpn4dJ+Vnl+nvpdSWABX96csQH++nvYv97VqlXEeGMNEAYso7QAP7bwAAATQtcpd+60sJjTHD4+T/ufs5gouqe/PKPjV7oqoQ7enEn+UVzwj6tkQesoeTfxfUBDwg6m45s0aShaBN1Jg3lMwmQ7PDUejSnb6k9dQz5A2jQ7N6ywhiNTI2MqZ9KNV4jB2eXC5obJlA7vRWhDaTQY/VD5xhCe8wvo2VnacoLsHR6KqmxTeU3OQpUCMdfv4GYQkzIAEb3YDvyEaZiWR2Oa1gNiTU9ZsFa34Ford8zJqx56CuuPd4VIhyhqH558/FRW5CVL5bhB3N3/30BKHwVcRDh9V5gffO6JQ1JbJRtf+EFyteP6Ey+HTmU/LQT1LuJyumStIQN4ss1c5IEujOOcT2DhgGSX+v5p+hZYUA0Gl77RMJ9Owdr/Ao6M2dDRi6PLNPoqOL5ZEamDKLMwwbwDBfWaLux12u0aHWaM1Q7tXc4ExDAATcrKejoNcdWdLIR4P9gdKMBOhfneqq2o51yfha347IT4OTKJGpibO2A1RlFNfPzQJyoGEKKg3NxVKMX1RolO8zK4em+a2fEjsjZ43ZAb33ss0HC3UAcrWhCtj6XMPN6DYiYREKUlW9Z8jh7sJ7mf6dO6UK2N5yvgVJRoK5xYtC79h7shnsSStZ7tlNvF9RGziygcAAAAA2XwnBJmPzRefTcc9WJhRMBdTQA8Uv7R80z5xn/hKrMWy6nSuaZEqRLi36hJftO9jvP17K5ObN1J1YHC2vlnnHy4evhc8OqPONeROVOJKhcQYDY15RIdbopW/q3CxRkpemPQAwu2Y9tI6y3YamNVwHmIxFyqrVmiVKWx4APVPL1j846T/dqLIvouu21VkoluR6dVqmqiBjFphQQ9TqjzjXqJCluyOsRGxsa8okTxU3rN4lrRfrGrscBYDDUB2E3r9K0AKjk0GTEkxSY1WrNOeOsfbjDaHnOzlbRp+1IwYuF6Z5baCtR1v0YYGk8pPD8UTX4Iep1zWxT7Bingg2VdV7uBsa8o2SA9/EMomGmmdgrZ5UKzW/6aRrfAtqYb9zNfPAr0ns1MO4yELlI8oZNSO8zZwEbhoR1K0FUKEu5ZpTK2ptGc4Oc4N8kxgQQqIqmoMfPDcxuIvJrTugPIn+y/lzaShOKOdwST+dRkUjgvez6QVfxrU0Z23ID0ZDykObTrfGCAufdL+h7fH3VzKZvNSv7p6E32MBsi0/R88LKxexDHSPZo3vPhBRLGKRpu7NUxVQJxg8gdqqjdlcc3yL3BjxZhtefpFUk9oGUIG/FIOXeQeFuJ9+Env5zw8KFmMTQKgWG0Whu8zL/hkk/gEu8Gt1Vi2qUi8hPo3fUOgX/XnoQBq/deRRQUQ92Tsu5x4LBhazyGs31tzGFZV8URSXJNc0IGTQ/TpJdsFmY9pO/CkRbjMFArSN2pAfQYVnu5JOh0vJzzCRxkbpv/H4GGlGygMXXJq9w3xFytPniDzBDK2GfjaOOpzlHvU0HXhuupoksIN9p0vOPF5xcCpv/mMmtrET+t+bISpfkDop+hFhmMlti4It/Nomnz2Yf9zVnzUkjS38AyKhz5pdH8CeEVyGW46defOiMLozr6vd4PpzWVTzipJAfXTEOECIrbj68s5or7G4+P0stVIyxtw/hdpae9TQeR7u/dLTS8OtKxh8aN9iLQ9HjREI6Fke1D8CTtECBpOHhVcG7Pw7lHzP4G/qZhvsA8oeuvlwiJcgMbTy3J+PKpTUfLooQJ8UI0Rq5M+QUm6S2eZLFp2IgIoC93g+nNZLXUiFTTZStQg4ATPejyaY0w2MG6w014GKNS7Lfa+RESvhDMUDDYS3i00vA/ugdOidT/kYsm/O5kZolruUW0YceF03JZIQqHA1m38HAR6n3P3DugdZ5i/6WHWhuBcP7DKHxB7WDZuk/P61lgSJfLJUsaGKh+yUsKCthSRcUnz2W7OBF7ceLRSQjFL4n0vK/bQISEZWa3wsajYE74/EuqX+346d5aJhkJdAnkwcp7FOYV7UW6DC9qsG7vWI+8BDGBBGyMLNyJ2bkqAquaKe5qtsmrfXG7LlKk8OCWa+ylpOTfm2aDI3GNVZojr0HY77fJESaIbgL72JYZk0rnDojffyJbF1C/B0TVaceOoaq5+kf/FcpKifQvhU74f5nTM6ZnTMu3qBRzIXC3upHVec4cTHZFEq92BKrjCxBg1gb46OePebTY5XjmRgdxJqEmdnRTRVMjsCI5fD7ZfnWDs5zShQAVfpeQjdi3NVtMmpsf/AFszMxIjjELo6bKV9hgY4MG8Ah93kPpzBfOEEEszN5CW0RWu2Go+/I6VyU7vnhPWI5OaoiX0OqFCj8P1s1pIB7rDSBX+x6cG3CXIdspo+ZIDoFfGoinRrs2Sh8Lp/v5lab5ncVTbLgQnyLoZEZRlIhTRVvN5lumqD0pGRyUs/pvOBZ4iyV52E71Q4rVi0vrKFYRiVBzPy5unrxaG0G+bP+zYCNopOwpCJFVv5HsLiv2Ydwso7s1buT6w4m2AmwhMpcvoYV4LI95wnvsYsFCXzyebMha4yIq9McHvA/1jFSfxBW3tc8oyyn71GtVvgd2Uy/HjPWPQPCH8EY4LBbQxc/krEfYHg/zD+A5+tVNZJVpwtHXO2RfVLAO2oKkhOjaoj4icN3aFjuK4oUnLeY8tCQLa3Mb8cBT6LhtmeuDBO0+O42qDukbXMXFatUXX2cwDAJ1R/RRTBxFMfNH1DqrZIirlKx7Qop7ljkCvLMlKcZQ0a/+AtNh8xzQWYMlJiXiUOPL9mRvffELYtSbdse0s31AMW3sAboQ3XITjIX4TfyYd/k6JcCm0Sl9TwHdwoxLDeBMM1RXbwHbKsQHtCUHPf/vQpoOfStCZLA/xsfQIP4+CAW8sJ6fHi9xbFC9c+95kjQOAuRPikJgn/a8fZOlyZBVL2GUC984MlNJ2CEt3P5otF/pN2ywcYP/PSHHu8ehT44r0XRcHOjAfA6voDFYBvvd26/bYAY3zNtuxfe66gpt/cA4uky57eYbXbk9BmqTWQ0bI5x2EnklkF+5Inc+8/jb/r8cDoBJuY7s70Zg45V29ghiCLoW/dLOy6xayTbAq1hCIsoro32hu4d2jUn7EYY2+VP9ouU08Kmn64meYQRw/bHvlD5iVIwOhY1xyW+q51Ch8Ui03fF/jQkMxaKcWeyjJRFqwiXOfRgJaKlballc0vwB5WFxQ7ZyOxCDd3rafd2Y3B/3FXIxADs2+Ds+/4stNaURXL09kzlXFQAWfTrQfiEG8bahod/uE4v2AH2UeEJmgF09OhpHj9kzXK6zHRYW8TCf2kgpv5Ej5CPL8JJ1GyQ668qMzL6WYp64DHhZ3dPiY3aQGgAFwyMaUWbmk68x1OzDGf8CfxqT4UecnRuxgaIxfBX9nFlDLp/2vjhh9MKiIiBDbohy0Lf9EmwFssUDCesaarYpDYT8YmAf0eY5HYVLYUhvs0HQqnpSgZhFBP7R5gGrsFrsM1lrwGCd1uLBr6XbwTjeI5XF2j7rQwIHVtNBMkCKn9vDNBNxldVzRC7zTd6fJ09MeNfkibdjudvDCVTAtwKsAJ4vgrIqeV+G2ufP+juO8XQxPyzhv5jz62jsiPtzHMKFSe1ubeiDW7A5rZV3WISp31j80nHlOWm+yBWvhRBc/JtgpxXXCK0ugzD4aIHb5mTzYJVU0b2/DRrqbkqQQmdu1vPntKAtBBq+lv2wdlUr7x7Z3JO3Hs84qGe2hDp0Z6/0x/LhmJENhglIy04+7UJFQeHws074CFDnR+oQ7Nqg8rHSfHUyCPFEXbOT6y8Oe4bp9oRoMN4rU4dy7iOLX2T/tyjrvSXjhF9BDkEuv/JXQhFODMpAptYDgCYe0hhGf8LLYS8xkKRyYnwsTOl/oBSASad3uXZ1ss44rAHpl7k6GlTN6T7rpSZf7Tyg6BYFcbI8RK/CNI8Kq7vEXE1RAt2SPl0PMNqLkLdfdp7lNK1wcf98KjXvlsZ6p++SFiIyS1d1yzDaFtdD9jQDLNTBjchT3qlt0RVh2o1qvG5x7O46CiWbWjRf12morY7y3KCtgPF6Vz1Rv6Ye/A+kFTAN+XOMfXtXshUy15mDtID8oG7kmK9G0yGPuJABUvsg/KoH6x9RQr4V1atgi8gfREUVAvWA6ZTogFQwFhKYYuPXxFeaZU6FvTTMUqGxrPm4Ly6NQ7QHluXVStm5x8al7oFrgb1H2sUgvH5v7wNFsxToqYafG4kxxneTNg9dMzIpaUWV+gVmQ1Rw3qOmCli0AG3g/cI91DgF0nMgRohDWVZOVYwmXFrG28nPjFuY7iIJlAptuukwbfvMooPuelorhPm6U1QZ6Q3E4LYsZqc/rwbnFFfgj0qfqwYlA8Inf3sdNvP2HrSoa4VsSc4fANrwWeblNuD7Qdyupt1nGXjTfaemCMWxQERbuX932lBdZJVN6WbAt4vrXYXIIlugncRLPTSGT1ZLKKX9PnSqsTVLNmhkjU6rj8M/d7wtlJgBi0OAqXiE3BY5wVq5cl2AlQOo2PxTyX5cOohhM9j8HYDZHyR8YKPOmcBzc7EN8oORqgKJO4Dax7ebEDOdxLxuWW+rFM8sba2D+dcDvXIo28h/aa0stCulsP+vw7iljdoBOe7wa5pnhChLIw9Ix0FxcgIscALVd6IkQ00oAG0xYherBhBeYuOSGqe0YfuUzmQXqpXIkXICNaMv6AilY+CHyD69ZjDkb8UvQHIFIgGJBqnDWzVxamnEBC6LSjQuWMSWJNhd1Pv1VHN/hBoPzlgYZRFxNO1Fqm+9RmWoBxmLsKGtcd8v/DdjXwMJc0LZ/Do3FNTZ8DZSIF/wv/UGV2+wYAb/P5LtJqwPcBhMT5iTwAQ3eMWrSVbo0lyOc7R0W1Byl90RTm9K8sqF90uJtVkLdBrIRoiOryKosY4OBwiwecqWk6x8DfQqH5X00P9ZnsOE88EpdcUCYQ1I68wPyaPMVkWnjKcFhYA5yrhh/Kp+LJKyjjLCHeseCSCWabTAdeIAh/EUdVP7K2bK8xCttGHsxtQc/YAgHpT9tcJPqkItJ4gBDR/TyOp3u8WW6CiwyLr1WzvuwK5FhMNCdde9NPeRskT+UpLf5aB9q6NNxPbtE5FlAZtqqmPHeSr+o3fj63PLCwc/d8l1m9dfOFCFlbMynNw78RXNyjsTDMxFxs8CBFT1GB6jzwlQkVED+EQd6ylPFoGhvCoyAvJr6RaI7S7iT1LNgQ3DAeeezbSAOtLu7S7135J5itOEdVCWnkkKK0pOJKBfZaGbcVl/8XHJ5GRvtd+u3+n7RZMg2vCyFRdz+q8ziC3jBSKXLeTQvJqUDYFUvV3OhZTgzqEJ4z6tpStlqoy5bQ4lJCnPmXWr+pDyWX/2Rk2Un8GRBx74LDVRaDPKAatov+a+woRphDjCDl3LL/QVPMION7aFYmYwZWx7YAD/JI1wRflPafdvrt3VY0TwpLTqRJJli3Tc4pw0LjnaYhRAHb6TipQYZ1ANhZHiVLTfCXiQ0YevIf3fqWdp3x1DNSPWDD5gVtWeLHKAsMiiDakRdASHt7tXqOUkR7MSxyfiPFeeKsrvK6jYO4Xe0DMjLmWNJ7cjM3JEk6CihXzcy69exg9SMuU+PyfsTwc9+4PDo1ogyFrTT66ROQiitZ6M7kpuM62i661XmC9ZlO6KZWXBoR7S3GORhyatihTaBzru3Z7ZCrfx+on02EvKsRuXMyUaTxCCMcM+eBqh98KETENtl8tIZjR5ZYnxTjxsDbmYns2xjSe3JV8hgzbUL0C5ltb6RjpxK0So5qFdkJ6HNtRjZ/mwVtdMZKdFkU55lY+8ZVNDYAC0B/2ZFJvWxCOPkXwzIDopjUIAR4xtDhmOPx5UcBfCLHu/zkXiaEiLjLpRQ0Z2bL7QNuS5fcDmPSG1/sNfQeaE5e8Qc91RWPjgmJJGBDEXVOA/h0Xhaj9W7ogEbdV7P0tHfe3iLoWmXkEtcP3ni35diBOmeZpsnaGnaJxEG1/YRK4Qd1Mi5H8NEEMUHO34HLgbZif0HzG7CQbeaBqoMgm2xYyCA556EAn4kcpj2j4hm5v4tXNQ9D0nwoz8n2I8kPAytXpTtnVIeQ0gJWRKG/IxOVL3yfyfkPlBcDT8Xv9e3E2hFfRPETVEG++nSOhclizKOBk9AMxvDjFJwwdFhoai8hstq9FehjPYd+Ixn9lR89fJvJmJAr0wz8oxaHylP+w91giSzg6SzQ6teLK0Z+PVqhNHA9qUt7HvVTCiuvZEEBwCaKxxGGrSDHdT+hRHN7o7UeeDC05kq0MtKg4ZhqyTizIPxfumn06Qp3DvfQoRo8T4sZi+spkCXGZA260Uu3cgtaG2f5L7qL58BmqsQnFTaxr2napr1d/IUpt+1hust2bLwn8dEE8cXJ+etO4dhyl1eP8MMNb1kcfy8LSV3PCAJImhPuFQjLX0evVNb9S2CS/noJcLA18y/YhStFrFcnyDa4B3eoT7AmjryQYO6fNus3QBkfY+C2V+ag4uN3VoNfI+eXPPY3izr0bPDe/Ebj3F1Bej1TyMWr6jL0tfd/FFUcnwlSirya5fjr7kesaLH55PdRYb1O6mRcj+uWGA4GWHehmw3oLbLP89sTspXH0hwT8jSU/FtbNjkD551ES0111lInxEw6DHaUlRlxbIPYWLHgMy7LEh35o1bZuxG07ino0qNUqUZOTUhO1bibktcsIRROlBdSTecKDt8XYiMg7yi/guruKuJL0LHqGEbXSGUU23uT+KDDrqMvjtjkRFKBp0ww3Zj1oDjDkIQTROzLcZ+fy5IecnDwTIQwIce+Gm706XuR2mXbUshWZ6awgUWf/AAPGzLiYys96ng5l2EoKKGIe7GCtL7Sj9R7JMUOi+8fJmKixSVgY7Ab4Bh29I0fk1yD/uxGr2Zu3jw7ni55VZbCTKNE+h+SiQmnB7WebAB4MOxSNli/OnMejysyMEiFw67ATTRnD386Cmn75F7omH54wP/A7ieH8i1VB79fhiYoui+CUWsK/lJJ94veKrKbqC6a9buL/xlahfoVbLw3KMg57AwNCUxMZ6tEjumvJJAuznD29ftQsHVfjYrmQMVazWeJgr8ekOwQPjnoUtl3XRxwiOb7ZijBXkfy1IUOKBD7sup9mV4S3PaUhM58jeOMJwbDNfpft7GzLGe2fUxZa4/tkvxwy5fUCI5/kASUUZdiVrUuDNV3spldjs+Hs5JW7G9Qg0gcFaPWbECXmbHLHg8TMMFUYQ+qJNKVE2itbKyDs8NxG+sY71hIaJRv64G1N9vkbK88GvT0Ix+ezNVMeRU4OHuenKPqx6UkGISsCyPB2kWJnOD2pLQhNq6eId6c+URfudN4zd0abDIftwCViiMmrxwvQCIy4IZtL/mp6p1nZGSdtuKkrS+qgCFkWvEQoofGfqopfrPjC/SWIcOL2ML8hzvckMB+SNGfdFKZHkQUvhZgiZcqPqWE6/quiLgAfHfr/uS29bwPs06I6xKgG2/T3V8BEL8mA8+Hc4j03zEM4y47gE1TN47tI+3ox2Pp74cPWQII0aflxhI4NMGaQN8RfjpBo0Tn2BPQ+dN/tYZjgVyc+SiEHR1bH5tpEd0tKXju46MazwhtVeldWtL3/WaV8l09He9bXaUK99TvXw8CBPnxL5c3NwSzx7jPjuKPYhyjlyR0BX8h5B3h7+kQGN+Y63aEAuIum9tlNhS8LtUOHbGd4DYpNg9lOl3XIDi558uQeb/Cl/U1UmyCRNtIjusvADIHtpSA52q3XRWuNUGf+GQBZt3UxBLH8AAoRXjV61Rmdg0earEz9ILQsvrIZhGhPqvVNBhZTBifpY3dTelrPVv6yfSVarcmEtraw/4a5XXFsrza/L5qI8e1dVBqJm4LoOPuFsZd8nIVP/nq7r9PKB2k27912X466aUOkgN4qbb80R2Q8gFcMtlglT0C1npPNda5oEbexnMsuFPtvhC+dhlnaC4uhYIYC1uSS0iKv4VPe6xIoAEfYv4johyDB5Wvww200d8OQW48V68eFb5blwktrx+D1Hjd+q+qDsrlRicO/RPk5CHgXjS6WEzh1t0gAoCWhiifTJC0iKVDj9mtlzJ25v3q8HGygId4dUD2dft+bdIE0rUgV6Qh60H8NK3cMJt3EhN3+D7b/dSyU6c0UkirMtkW8v9B7u8qcJeZ5sbwBuUwR8mgdJEpGHekVb6uz9hlOpR8WDLdy/PZY9+iUlbnL/6srZZYOPgEAoFvcXbc50Vl830gJzllTsk5Mup8w5ZbmSNY1p5s9G/j1rlixeZxwf8Z5dgZaFwgXdbV7mxpeT3+b56NEQVmRqMKi7lFSjGmI4eQaDpzYmfQ6OY43QRfqqkWdOGNY9QBepQZ/dLCv+PWuWLF5+g0nVP4BrEmg6rn9/2R9IOKrJsz4MqWrRkoT7RhZDjQ8l7L9qUYzOGus7O96d3Zlh6GQO1yg3LVOebHAzMIblCTX+QVfwXwFUXGBdVTpERgprPvhcjRHyO3ZNicomfuZqaeNOL4PEx/vGh7/4pWFv3AwR7UIffLjVH6dNyj+/M8bbzlK5KcL7E/PXp4+e4UmdmIRy8OVnpqo1yzXNt+HpnTqry+OEvvB46iaqU5438AIqaxtgb0K6VEUW0IUvzt2PoSE65U2RiSbFwzIJQqw7O6LDvnO6VUCqKzgo5HdggMax6WY5F/zmuiN52Zvc3Tkrf6J777sxU291TmFvtJmcGnZIaPzua9EMBModpfcurdPtTr0Z00KTyD540sCef59oozZuzzOrGvnSGEQIFE70cdM8+DHvcMRZcplwOCsjA9INln6pThc7aSfTivu/3lWwqEWV/u8RYURiR9VxAqFnolQUgMgOFkBBtYfDLjw6qU28DVcFGZdrL4W19IXM2ZjuNd/Iffm/bshHCuuFgAV84gf+P70WpAl/TMwzmYyMNyAWh7EFz9k2zqs5uZjC9jg+aVmetWqNBn0p8VWXQqjrjo9XbpxMx+DnVIs/2N81ldDTidtOUn1gGThus1oM5II4GsGvUny/JCb3c2Gw9jMpjd9QkskyztlWBUmt0Ukpwe9SR91UmgRwUxCRL1F+6leWURWLumUm9DpTzObCFPPAKJ1fyj5B33NZ/8/4nr8sShf0awgWwhu6G1EBT8NGHO0ekylViFkFDuVD6PyPlSTlyxa7pFoVvQEx6byltPYj3/gziZqn451APcFNsGa0u7+yPuDEqaU0SknFXEPNfN9KblROSF3QSTdebQHkAuSsrtt8+XRECeUmWdWmu/PwBVMDrqSBpjv/SYGFnI32hIn9aaaeKoIgYhNcLe9tlObNFWce9ssuFPtvhC+dggWpl2sFbM9S+Pk190nPv7TzbyprTqhWaDmA3isIdr7+EXRuymTA+bHawbpU8VyKqU05+KAXkgsmbFPr4wQQzf77nMVuo7twOmzqXlIQXzneSZf3bDjRdFjyXfj3aLl870dtcnjhZBsIXC3JJLH4zcutLmGDqHoJYXb5rnXOJKgwCprlfnrbbOfSWqvRlmCo5v4gvjJfaD2bsCKD8uEOXJl1TqI5LIWpnPJ3+IPbSq8l5x5AtescQrtlGYoOkpVWuim5Qrjsy3FR7Bfo2WLUlxfXD4lkGeanW4lRIl0pLbvxcxfwyEk2/SKy5b+19oTtTPIGqikLjCXA5+pim2QsCoI6uwDLigEWpbC134cuTiCtEP1qDKWv3K6PDf0aEg+AiKCGzz3isQ/Wojgm8folozJqLJrisng8lKTySQM14Eb/UP7dIcpRpSxb57Ql0+uik81XX0xfnKdz9E5WfYTbunNMER/NAJop5u4GsIKZlIAI+Lj8j0TGYRvKUEbl/gWZCB92T2id/w3xPfldwk1P/p0UdcopSy5NycQ8uvTqnECPMRtLIAwYtcfkBjb/qDRU5m6HCQ99moh4HBDYjFC0gSbOqTmeKFumIb79wvYv/xE1ydWESpJ00fCSADam1Dkw2ELvmKNFkrP9IDcCYyATeaHhEFkW/IFEGkeS4gjHfudtq+EQVZW+Jzfi/S457oV4FoUQu4XzroO0iXwWR9cWCmkQ9aH56ZAhk3NgFcXJuVm1mkcKEyPsWZ1vnsgyWCjJnzeS8kTCbyHNG9btPKnqnNABOKF/s81O0S6fZqp4tuVzljdQ9aDvUIusgbl5EL3xWvWznWRxbFcDtU7h8fCNT0nXRshsyKtIHqFG8/iJ+Rl6UxwaR6fcjg2eJQlWXZkaEulNs53ys7IrO3DU3CD6b4nFedpuUCw6S6R7TEqUyjEKXkgfjRQULnx5drE9a5adELf7SgO0dJz1cUSy0CtZ2c07KPE1xW8urWrALcVu3JpTRGMEU3OClMNsh2JyPLsyKGXFxanW/ACS9IMTLbQjZpBQNOltjc0Y5pBO1HwS5WMKsWq3IsBryojeOFpaTXhGuByul0W4Elj/hnbPB/UuPFmZnyKX5QQTs40mqxawSHABMu+oPOBRElsoDtGeCDopU/g7uDVpH2AG2JQ+++bDF/PtsQZYUjoTh2zUmSlkYUiIKkz/CevXOAM0UBGWiuoGRCkqxP7MQwTY2KxF6w5Fvcwqxl88bP8YEhh9f8FsAK9RXYbAljb3rXJ7KNXbQ9kABilkAeujJkFyzZvgaWXvP79MkZNn4s2wfi+P2lyl6JmsqMqBk1XMcw1WhX3vYZg0l4TI6RKVhNacS4sArUkFi4X3Rkenvdpz7KEo0meXfRq8fEOj75maHXoXPWFIdC2oeXXvyhJdXrzzMAD+3AN7+IljvDybuFD7kjNKVmgQOdUtacSFvWB+Kq5jmGqugI45JALRM1so3PAOvVvyZvLEAAAAEVYSUa6AAAARXhpZgAASUkqAAgAAAAGABIBAwABAAAAAQAAABoBBQABAAAAVgAAABsBBQABAAAAXgAAACgBAwABAAAAAgAAABMCAwABAAAAAQAAAGmHBAABAAAAZgAAAAAAAABIAAAAAQAAAEgAAAABAAAABgAAkAcABAAAADAyMTABkQcABAAAAAECAwAAoAcABAAAADAxMDABoAMAAQAAAP//AAACoAQAAQAAAFQBAAADoAQAAQAAABoBAAAAAAAA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLo5qxOUdVt"
      },
      "source": [
        "There are various approaches to employing deep learning models for question answering, and we will explore the intricacies of this task in upcoming lectures. For now, prepare for a hands-on journey into loading a pre-trained BERT model from Hugging Face, which encodes questions and context together and answers by selecting a span in the given context. The model's output includes scores for the start and end positions of the answer span. Follow the instructions in the provided Jupyter notebook to complete the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbF3j0paCyCa"
      },
      "source": [
        "**(a)** Load the pre-trained model and tokenizer and complete the `__init__` function. **(2 pts)**\n",
        "\n",
        "**(b)** Implement the `tokenize` function to encode the question and context. **(6 pts)**\n",
        "\n",
        "**(c)** Complete the `generateAnswer` function for inference. **(12 pts)**\n",
        "\n",
        "**(d, bonus)** Add a condition that ensures the end position comes after the start position in your inference code. **(4 pts)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cLypk7wBF2_3"
      },
      "outputs": [],
      "source": [
        "class QAmodel:\n",
        "    def __init__(self, model_path):\n",
        "        self.model_path = model_path\n",
        "\n",
        "        ### YOUR CODE HERE (~2 lines)\n",
        "        ### TODO:\n",
        "        ### Load a tokenizer and question answering model from hugging face and save them in self.tokenizer and self.model\n",
        "        ### Hint: you can refer to the following document and use given model_path\n",
        "        ### https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForQuestionAnswering\n",
        "        \n",
        "        self.tokenizer =  AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "\n",
        "        ### END YOUR CODE\n",
        "        self.max_seq_len = self.model.config.max_position_embeddings\n",
        "        self.splitted = False\n",
        "\n",
        "    def tokenize(self, question, context):\n",
        "        ### YOUR CODE HERE (~5 lines)\n",
        "        ### TODO:\n",
        "        ### 1. Encode the question and context by passing into the loaded tokenizer and save it to self.inputs\n",
        "        ###     Hint: you have to return 'token_type_ids' in order to be used in self.split()\n",
        "        ###     Hint: you can refer to the following document for tokenizer\n",
        "        ###           https://huggingface.co/transformers/v2.11.0/main_classes/tokenizer.html\n",
        "        ### 2. If input length exceeds the maximum sequence length, the input context should be splitted. Mark self.splitted True if it is splitted.\n",
        "        ###     Hint: use given self.max_seq_len and self.split()\n",
        "        ### Hint: this function will return nothing\n",
        "        \n",
        "        self.inputs = self.tokenizer(question, context, return_tensors='pt')\n",
        "        if len(context) > self.max_seq_len:\n",
        "            self.inputs = self.split()\n",
        "            self.splitted = True\n",
        "        \n",
        "\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "    def split(self):\n",
        "        # this function is to split the input context if the length exceeds the maximum sequence length\n",
        "        question_mask = self.inputs['token_type_ids'].lt(1)\n",
        "        question_size = torch.masked_select(self.inputs['input_ids'], question_mask).size()[0]\n",
        "        split_size = self.max_seq_len - question_size - 1\n",
        "\n",
        "        inputs_splitted = OrderedDict()\n",
        "        for key, item in self.inputs.items():\n",
        "            question = torch.masked_select(item, question_mask)\n",
        "            context = torch.masked_select(item, ~question_mask)\n",
        "            context_splitted = torch.split(context, split_size)\n",
        "\n",
        "            for i, context in enumerate(context_splitted):\n",
        "                if i not in inputs_splitted:\n",
        "                    inputs_splitted[i] = {}\n",
        "                input_item = torch.cat((question, context))\n",
        "                if i != len(context_splitted) - 1:\n",
        "                    if key == 'input_ids':\n",
        "                        input_item = torch.cat((input_item, torch.tensor([102])))\n",
        "                    else:\n",
        "                        input_item = torch.cat((input_item, torch.tensor([1])))\n",
        "                inputs_splitted[i][key] = torch.unsqueeze(input_item, dim=0)\n",
        "\n",
        "        return inputs_splitted\n",
        "\n",
        "    def generateAnswer(self):\n",
        "        if self.splitted:\n",
        "            answer = ''\n",
        "            for i, input_item in self.inputs.items():\n",
        "\n",
        "                ### YOUR CODE HERE (~6 lines)\n",
        "                ### TODO:\n",
        "                ### Get answer from each of the splitted contexts. \n",
        "                ### Remember that this model predicts answer by span selection. The output will contain scores for start and end position. \n",
        "                ### Hint: Use torch.argmax and given self.convert_to_string function\n",
        "                ### Hint: You should note that in a Python index [A:B], it includes the element at index A and excludes the element at index B.\n",
        "                ### Hint: you can refer to the following document \n",
        "                input_ids = input_item['input_ids']\n",
        "                output = self.model(input_ids)\n",
        "                start_logit, end_logit = output['start_logits'], output['end_logits']\n",
        "                start_idx = torch.argmax(start_logit)\n",
        "                end_idx = torch.argmax(end_logit)\n",
        "                ans = self.convert_to_string(input_item['input_ids'][0][start_idx : end_idx+1])\n",
        "            \n",
        "                ### END YOUR CODE\n",
        "                if ans != '[CLS]':\n",
        "                    answer += ans + \", \"\n",
        "            return answer\n",
        "        \n",
        "        else:\n",
        "            ### YOUR CODE HERE (~6 lines)\n",
        "            ### TODO:\n",
        "            ### Get answer from self.inputs.\n",
        "            ### Hint: use the same approach you made in the previous question\n",
        "            output = self.model(self.inputs['input_ids'])\n",
        "            start_logit, end_logit = output['start_logits'], output['end_logits']\n",
        "            start_idx = torch.argmax(start_logit)\n",
        "            end_idx = torch.argmax(end_logit)\n",
        "            ans = self.convert_to_string(input_item['input_ids'][0][start_idx : end_idx+1])\n",
        "            \n",
        "            ### END YOUR CODE\n",
        "            return answer\n",
        "\n",
        "    def convert_to_string(self, input_ids):\n",
        "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
        "        answer = self.tokenizer.convert_tokens_to_string(tokens)\n",
        "        return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb5uAIjaFPkV"
      },
      "source": [
        "### Inference\n",
        "\n",
        "Now let's use the pre-trained model to generate answer to the questions. \n",
        "\n",
        "For context, we will use Wikipedia, a Python library that makes it easy to access and parse data from Wikipedia.\n",
        "You can refer to [here](https://wikipedia.readthedocs.io/en/latest/code.html#api) for use of the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wOA1HqIcGAXA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Who is the author of Harry Potter and the Goblet of Fire?\n",
            "Top wiki result: <WikipediaPage 'Harry Potter and the Goblet of Fire'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3489 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: J. K. Rowling and the fourth novel in the Harry Potter series. It follows Harry Potter, a wizard in his fourth year at Hogwarts School of Witchcraft and Wizardry, and the mystery surrounding the entry of Harry ' s name into the Triwizard Tournament, in which he is forced to compete. The book was published in the United Kingdom by Bloomsbury and in the United States by Scholastic. In both countries, the release date was 8 July 2000. This was the first time a book in the series was published in both countries at the same time. The novel won a Hugo Award, the only Harry Potter novel to do so, in 2001. The book was adapted into a film, released worldwide on 18 November 2005, and a video game by Electronic Arts. = = Plot = = Over the summer, the Weasleys invite Harry Potter to attend the Quidditch World Cup final, played between Bulgaria and the Republic of Ireland. The match ends in a victory for the Irish, but the campsite is attacked by Voldemort ' s former followers called the Death Eaters, , Crouch Jr had then been placed under the Imperious Curse by his father until he had managed to break out of it during the Quidditch World Cup and cast the Dark Mark. He had then imprisoned the real Moody and impersonated him using more Polyjuice Potion. Arriving at Hogwarts, he made sure that Harry won the Tournament and was transported to the graveyard for Voldemort ' s ritual ; his only wish is that Voldemort rise to the power he once had. His father had been placed under the Imperious Curse after Crouch Jrs escape, but had started to resist it and so had been killed. Crouch Jr is handed over to the Dementors. Harry recovers in the hospital wing, surrounded by Ron, Hermione and the Weasleys., Triwizard Tournament, Oppressed groups are not, generally speaking, people who stand firmly together – no, sadly, they kind of subdivide among themselves and fight like hell, sleeping car, Rowling quickly gets back on track, introducing readers to a host of well - drawn new characters. ' Writing for Salon. com, Charles Taylor, \n",
            "---------------------------------------------------------------------------------\n",
            "Question: Where was the 2010 world cup played?\n",
            "Top wiki result: <WikipediaPage '2010 FIFA World Cup'>\n",
            "Answer: , Morocco, Ireland, As of 2023, this was the last time South Africa, New Zealand, North Korea, Paraguay, Slovakia and Slovenia qualified for a FIFA World Cup finals, and the last time Costa Rica, Iran, Belgium, and Croatia ( only time ) failed to qualify. = = = List of qualified teams = = = The following 32 teams, shown with final pre - tournament rankings, qualified for the final tournament. = = Preparations = = Five new stadiums were built for the tournament, and five of the existing venues were upgraded. Construction costs were expected to be R8. 4 billion ( just over US $ 1 billion or €950 million ). South Africa also improved its public transport infrastructure within the host cities, including Johannesburg ' s Gautrain and other metro systems, and major road networks were improved. In March 2009, Danny Jordaan, the president of the 2010 World Cup organising committee, reported that all stadiums for the tournament were on schedule to be completed within six months., US $ 9 million – To each team eliminated in the round of 16 ( 8 teams ) ( $ 12. 08 million in 2023 US dollars ) US $ 14 million – To each team eliminated in the quarter - finals ( 4 teams ) ( $ 18. 79 million in 2023 US dollars ) US $ 18 million – Fourth placed team ( $ 24. 16 million in 2023 US dollars ) US $ 20 million – Third placed team ( $ 26. 84 million in 2023 US dollars ) US $ 24 million – Runner up ( $ 32. 21 million in 2023 US dollars ) US $ 30 million – Winner ( $ 40. 26 million in 2023 US dollars ) In a first for the World Cup, FIFA made payments to the domestic clubs of the players representing their national teams at the tournament. This saw a total of US $ 40 million paid to domestic clubs., FNB Stadium, Cape Town Stadium, and Nelson Mandela Bay Stadium in Port Elizabeth were the most - used venues, each hosting eight matches. Ellis Park Stadium and Moses Mabhida Stadium in Durban hosted seven matches each, while Loftus Versfeld Stadium in Pretoria, Free State Stadium in Bloemfontein and Royal Bafokeng Stadium in Rustenburg hosted six matches each. Peter Mokaba Stadium in Polokwane and Mbombela Stadium in Nelspruit hosted four matches each, but did not host any knockout - stage matches. The following stadiums were all upgraded to meet FIFA specifications : = = = Team base camps = = = The base camps were used by the 32 national squads to stay and train before and during the World Cup tournament. In February 2010, FIFA announced the base camps for each participating team. Fifteen teams were in Gauteng Province, while six teams were based in KwaZulu - Natal, four in the Western Cape, three in North West Province, and one each in Mpumalanga, the Eastern Cape, and the Northern Cape., FC Barcelona of Spain was the club contributing the most players to the tournament, with 13 players of their side travelling, 7 with the Spanish team, , Chile. European teams performed even more strongly in the sense that all matches between a European and a non - European team were won by the European team. In the previous edition ( 2006 ), they had also achieved this. England ' s 4 – 1 loss to Germany was their biggest ever margin of defeat at a World Cup finals. It was also the first time that a World Cup finals match between these two traditional rivals had a decisive result in regulation time, their three previous meetings all being tied at 90 minutes, with two settled in extra time and one in a penalty shoot - out. Ghana defeated the United States after extra time to become the third African team to reach the last eight ( after Cameroon in 1990 and Senegal in 2002 ), and the only African team to have achieved both a top 8 finish and a separate top 16 finish ( in 2006 ), Ghana in a penalty shoot - out after a 1 – 1 draw in which Ghana missed a penalty at the end of extra time after Luis Suárez controversially handled the ball on the line. = = = Semi - finals = = = The Netherlands qualified for the final for the third time with a 3 – 2 win over Uruguay. Spain reached their first ever final with a 1 – 0 victory over Germany. As a result, it was the first World Cup final not to feature at least one of Brazil, Italy, Germany or Argentina. = = = Third place play - off = = = Germany defeated Uruguay 3 – 2 to secure third place., , Diego Forlán of Uruguay had five goals and one assist in 654 minutes. A further three players scored four goals. Only 145 goals were scored at South Africa 2010, the lowest of any FIFA World Cup since the tournament switched to a 64 - game format. This continued a downward trend since the first 64 - game finals were held 12 years earlier, with 171 goals at France 1998, 161 at Korea / Japan 2002 and 147 at Germany 2006, , , Abahlali baseMjondolo took the KwaZulu - Natal government to court over their controversial Elimination and Prevention of Re - Emergence of Slums Act, meant to eliminate slums in South Africa and put homeless shackdwellers in transit camps in time for the 2010 World Cup. Another prominent controversy surrounding preparations for the World Cup was the N2 Gateway housing project in Cape Town, with revenue to FIFA of £2. 24 billion ( €2 billion ), Univision averaged 2, 624, 000 viewers for the tournament, up 17 percent, and 1, 625, 000 households, an increase of 11 percent. An executive of the Nielsen Company, a leading audience research firm in the US, described the aggregate numbers for both networks ' coverage of the match between the United States and Ghana as \" phenomenal \". Live World Cup streaming on ESPN3. com pulled in some of the largest audiences in history, as 7. 4 million unique viewers tuned in for matches. In total, ESPN3. com generated 942 million minutes of viewing or more than two hours per unique viewer. All 64 live matches were viewed by an average of 114, 000 persons per minute. Most impressive were the numbers for the semi - final between Spain and Germany, animals who predicted results of the matches = = References = = = = External links = = 2010 FIFA World Cup Official Site ( Archived ) 2010 FIFA World Cup South Africa, \n",
            "---------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "questions = [\n",
        "    'Who is the author of Harry Potter and the Goblet of Fire?',\n",
        "    'Where was the 2010 world cup played?'\n",
        "    ]\n",
        "\n",
        "model_path = \"deepset/bert-base-cased-squad2\"\n",
        "model = QAmodel(model_path)\n",
        "\n",
        "for question in questions:\n",
        "    print(f\"Question: {question}\")\n",
        "    results = wiki.search(question)\n",
        "\n",
        "    page = wiki.page(results[0])\n",
        "    print(f\"Top wiki result: {page}\")\n",
        "    context = page.content\n",
        "\n",
        "    model.tokenize(question, context)\n",
        "    answer = model.generateAnswer()\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print(\"---------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
